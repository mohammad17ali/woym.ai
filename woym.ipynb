{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"1+2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T09:38:44.759850Z","iopub.execute_input":"2025-02-25T09:38:44.760119Z","iopub.status.idle":"2025-02-25T09:38:44.766487Z","shell.execute_reply.started":"2025-02-25T09:38:44.760076Z","shell.execute_reply":"2025-02-25T09:38:44.765533Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, TrainerCallback\nfrom datasets import load_dataset\nfrom peft import LoraConfig, get_peft_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T09:38:49.131660Z","iopub.execute_input":"2025-02-25T09:38:49.131951Z","iopub.status.idle":"2025-02-25T09:39:10.674600Z","shell.execute_reply.started":"2025-02-25T09:38:49.131927Z","shell.execute_reply":"2025-02-25T09:39:10.673928Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"print(torch.__version__)\nprint(torchvision.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(torch.cuda.is_available()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T09:39:17.423929Z","iopub.execute_input":"2025-02-25T09:39:17.424536Z","iopub.status.idle":"2025-02-25T09:39:17.478758Z","shell.execute_reply.started":"2025-02-25T09:39:17.424508Z","shell.execute_reply":"2025-02-25T09:39:17.477854Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"> Dataset explaining Neuromorphic computing.","metadata":{}},{"cell_type":"code","source":"#Dataset - Primary Students-Teacher interactions\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ajibawa-2023/Education-Young-Children\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T09:39:21.273687Z","iopub.execute_input":"2025-02-25T09:39:21.274018Z","iopub.status.idle":"2025-02-25T09:40:13.230318Z","shell.execute_reply.started":"2025-02-25T09:39:21.273985Z","shell.execute_reply":"2025-02-25T09:40:13.229644Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e76d4a31eabf4ed280ad77a85f9c60f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Education-Young-Children-0-Final.json:   0%|          | 0.00/294M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1410598e022e4eb7ae6e0c87cebf6c50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Education-Young-Children-1-Final.json:   0%|          | 0.00/292M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e74fdfa7ccff426da008f2ab3ad83e38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Education-Young-Children-2-Final.json:   0%|          | 0.00/294M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd65e809daba423c9d0ed843050c8cbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Education-Young-Children-3-Final.json:   0%|          | 0.00/392M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8bb70b6d44c4c00ae9b7199d1473e3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/255848 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9951264ca2142d49663a77dcf939f32"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"print(ds[\"train\"][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T09:40:23.704664Z","iopub.execute_input":"2025-02-25T09:40:23.704952Z","iopub.status.idle":"2025-02-25T09:40:23.710451Z","shell.execute_reply.started":"2025-02-25T09:40:23.704932Z","shell.execute_reply":"2025-02-25T09:40:23.709644Z"}},"outputs":[{"name":"stdout","text":"{'prompt': 'Write a long and very detailed course unit for a textbook on \"Fourth-Year Japanese, Second Quarter\" intended for young children.\\nWe have already covered chapter(s) \"1. Introduction\", \"2. Structure of Japanese\", \"3. Writings in different genres and styles\", \"4. Using knowledge in writing\", \"5. Expressing opinions on a variety of topics\", \"6. Original writings\" and are now writing a chapter on \"7. Conclusion\".\\nWe have already covered the following sub-units in the current chapter: \"7.1. Review of course content\".\\nWrite the new sub-unit titled \"7.2. Future directions for Japanese language learning\" while trying to be:\\n- Rigorous - you create challenging textbooks that cover the material in depth.\\n- Engaging - your textbooks have a narrative arc and engaging tone, like the writing of Michael Lewis.\\n- Applied - you use specific and practical examples. For example, if the topic is integration in calculus, include equations and proofs of the concept you\\'re teaching. As another example, if the topic is the history of the United States, include dates, names, and key events.\\nRemember this unit is intended for young children books, so use very simple, everyday words and phrases that a 10-year-old would easily understand. Tell an engaging and cheerful story and avoid any complex concepts or technical terms', 'text': ' Congratulations, fourth-grade friends! You\\'ve made it to the final chapter of our exciting journey through Fourth-Year Japanese. We\\'ve learned so much together about grammar, writing styles, expressing opinions, and creating original works. Now it\\'s time to look ahead at all the wonderful possibilities waiting for you as you continue learning Japanese! This section is called \"7.2. Future Directions for Japanese Language Learning.\"\\n\\nImagine yourself in a few years, confidently ordering food at your favorite sushi restaurant, chatting with pen pals from Japan, watching anime without needing subtitles, or even traveling to Japan someday! All these dreams can come true as you keep improving your Japanese skills. Here are some ideas for your future adventures in language learning:\\n\\n**Exploring New Genres:**\\nWhile we\\'ve studied various types of texts during our course, there\\'s still more to discover! Manga (comics), light novels, historical documents, modern poetry – each genre has its unique style and vocabulary. Challenge yourself by reading authentic pieces written for native speakers and learn how context clues help you grasp unfamiliar expressions.\\n\\n**Expanding Vocabulary:**\\nBy continuously exposing yourself to Japanese media such as TV shows, movies, songs, podcasts, video games, and websites, you will encounter many fascinating words and phrases that aren\\'t typically found in textbooks. Keep track of them using flashcards or apps, and review regularly to build up your active vocabulary. Remember, every word you learn brings you one step closer to fluency!\\n\\n**Honing Listening Skills:**\\nListening comprehension might feel harder than reading since it often involves real-time processing. But fear not! Practicing with audio materials like news broadcasts, interviews, and conversations between natives will significantly enhance your understanding over time. Try listening exercises where you jot down keywords or summarize what you hear. It may take patience, but soon enough, you\\'ll find yourself catching nuances and humor in spoken Japanese.\\n\\n**Cultural Exploration:**\\nLanguage isn\\'t just words; it\\'s deeply intertwined with culture. Delving into customs, traditions, festivals, arts, and social norms of Japan will enrich your connection with the language. Watch documentaries, read travel guides, join cultural clubs, cook traditional dishes, or attend local events celebrating Japanese heritage – these experiences will give you rich insights and make your learning journey enjoyable and memorable.\\n\\n**Connecting With Others:**\\nMaking Japanese friends, either online or offline, opens doors to genuine communication practice. Don\\'t shy away from joining conversation groups, exchanging emails, attending meetups, or participating in language exchange programs. Sharing personal stories, asking questions, giving compliments, and laughing together will bring joy to both you and your friendships.\\n\\nAs we wrap up our adventure together, I encourage you to maintain curiosity, resilience, and enthusiasm towards mastering Japanese. The road ahead holds endless opportunities for growth, creativity, self-expression, and friendship. So let\\'s celebrate our accomplishments thus far and excitedly anticipate everything yet to come! Sayonara until our paths cross again!', 'text_token_length': 681}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#v2\nmodel_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:08:52.766604Z","iopub.execute_input":"2025-02-25T13:08:52.766934Z","iopub.status.idle":"2025-02-25T13:08:55.625316Z","shell.execute_reply.started":"2025-02-25T13:08:52.766904Z","shell.execute_reply":"2025-02-25T13:08:55.624398Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:09:00.501778Z","iopub.execute_input":"2025-02-25T13:09:00.502074Z","iopub.status.idle":"2025-02-25T13:09:00.508712Z","shell.execute_reply.started":"2025-02-25T13:09:00.502050Z","shell.execute_reply":"2025-02-25T13:09:00.507856Z"}},"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(32000, 2048)\n    (layers): ModuleList(\n      (0-21): 22 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n)"},"metadata":{}}],"execution_count":104},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=8, \n    lora_alpha=32, \n    target_modules=[\"q_proj\", \"v_proj\"], \n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\n\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:09:07.993691Z","iopub.execute_input":"2025-02-25T13:09:07.993998Z","iopub.status.idle":"2025-02-25T13:09:08.072377Z","shell.execute_reply.started":"2025-02-25T13:09:07.993975Z","shell.execute_reply":"2025-02-25T13:09:08.071600Z"}},"outputs":[{"name":"stdout","text":"trainable params: 1,126,400 || all params: 1,101,174,784 || trainable%: 0.1023\n","output_type":"stream"}],"execution_count":105},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T09:47:19.440463Z","iopub.execute_input":"2025-02-25T09:47:19.440751Z","iopub.status.idle":"2025-02-25T09:47:19.467959Z","shell.execute_reply.started":"2025-02-25T09:47:19.440729Z","shell.execute_reply":"2025-02-25T09:47:19.467306Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def tokenize_function(examples):\n    prompt_template = \"<|im_start|>user\\n{}<|im_end|>\\n<|im_start|>assistant\\n\"\n    formatted_prompts = [prompt_template.format(p) for p in examples[\"prompt\"]]\n    formatted_texts = [t + \"<|im_end|>\" for t in examples[\"text\"]]\n    \n    # Tokenize inputs (prompts + responses for causal LM)\n    tokenized_inputs = tokenizer(\n        formatted_prompts,\n        formatted_texts,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=512,\n        return_tensors=\"pt\"\n    )\n    \n    # Create proper labels (for causal LM, labels are the same as input_ids)\n    tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].clone()\n    \n    return tokenized_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:01:38.127406Z","iopub.execute_input":"2025-02-25T13:01:38.127700Z","iopub.status.idle":"2025-02-25T13:01:38.132909Z","shell.execute_reply.started":"2025-02-25T13:01:38.127675Z","shell.execute_reply":"2025-02-25T13:01:38.131907Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"# Tokenize dataset\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n# Removing columns that aren't needed for training\ncolumns_to_remove = [col for col in tokenized_datasets.column_names[\"train\"] \n                    if col not in [\"input_ids\", \"attention_mask\", \"labels\"]]\ntokenized_datasets = tokenized_datasets.remove_columns(columns_to_remove)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:01:42.752622Z","iopub.execute_input":"2025-02-25T13:01:42.752979Z","iopub.status.idle":"2025-02-25T13:08:39.614708Z","shell.execute_reply.started":"2025-02-25T13:01:42.752947Z","shell.execute_reply":"2025-02-25T13:08:39.614011Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/255848 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"085669089441493c936f2df1ef0c8ace"}},"metadata":{}}],"execution_count":102},{"cell_type":"code","source":"for col in tokenized_datasets.column_names[\"train\"]:\n    print(col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:09:25.754427Z","iopub.execute_input":"2025-02-25T13:09:25.754836Z","iopub.status.idle":"2025-02-25T13:09:25.760156Z","shell.execute_reply.started":"2025-02-25T13:09:25.754798Z","shell.execute_reply":"2025-02-25T13:09:25.759202Z"}},"outputs":[{"name":"stdout","text":"input_ids\nattention_mask\nlabels\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"training_args = TrainingArguments(\n    fp16=True,\n    output_dir=\"./results\",\n    per_device_train_batch_size=4,\n    num_train_epochs=2,  \n    learning_rate=2e-5,  \n    warmup_steps=100,\n    save_strategy=\"epoch\",\n    logging_dir=\"./logs\",\n    run_name=\"padh.ai_FT\",\n    report_to=\"none\", \n    save_steps=5000,  \n    logging_steps=200,\n)\n\nclass DebugCallback(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        print(logs) \n#small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(10000))\ntrain_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(5000))\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    callbacks=[DebugCallback()] \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:13:19.755634Z","iopub.execute_input":"2025-02-25T13:13:19.755987Z","iopub.status.idle":"2025-02-25T13:13:19.862591Z","shell.execute_reply.started":"2025-02-25T13:13:19.755961Z","shell.execute_reply":"2025-02-25T13:13:19.861943Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:13:29.094141Z","iopub.execute_input":"2025-02-25T13:13:29.094441Z","iopub.status.idle":"2025-02-25T13:13:29.099308Z","shell.execute_reply.started":"2025-02-25T13:13:29.094419Z","shell.execute_reply":"2025-02-25T13:13:29.098564Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 5000\n})"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:14:18.896408Z","iopub.execute_input":"2025-02-25T13:14:18.896937Z","iopub.status.idle":"2025-02-25T14:12:59.204569Z","shell.execute_reply.started":"2025-02-25T13:14:18.896891Z","shell.execute_reply":"2025-02-25T14:12:59.203715Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2500/2500 58:38, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>1.864500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.989100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.890600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.855300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.845700</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.845600</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.827800</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.825000</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.824700</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.812200</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.813400</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.812200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"{'loss': 1.8645, 'grad_norm': 2.46943998336792, 'learning_rate': 1.9175000000000002e-05, 'epoch': 0.16}\n{'loss': 0.9891, 'grad_norm': 1.8559706211090088, 'learning_rate': 1.7516666666666668e-05, 'epoch': 0.32}\n{'loss': 0.8906, 'grad_norm': 1.9598642587661743, 'learning_rate': 1.5850000000000002e-05, 'epoch': 0.48}\n{'loss': 0.8553, 'grad_norm': 2.086113214492798, 'learning_rate': 1.4183333333333334e-05, 'epoch': 0.64}\n{'loss': 0.8457, 'grad_norm': 1.8515973091125488, 'learning_rate': 1.2516666666666668e-05, 'epoch': 0.8}\n{'loss': 0.8456, 'grad_norm': 1.826533317565918, 'learning_rate': 1.0850000000000001e-05, 'epoch': 0.96}\n{'loss': 0.8278, 'grad_norm': 1.8816505670547485, 'learning_rate': 9.183333333333334e-06, 'epoch': 1.12}\n{'loss': 0.825, 'grad_norm': 2.1385412216186523, 'learning_rate': 7.516666666666668e-06, 'epoch': 1.28}\n{'loss': 0.8247, 'grad_norm': 2.090642213821411, 'learning_rate': 5.85e-06, 'epoch': 1.44}\n{'loss': 0.8122, 'grad_norm': 1.9559381008148193, 'learning_rate': 4.183333333333334e-06, 'epoch': 1.6}\n{'loss': 0.8134, 'grad_norm': 1.969048261642456, 'learning_rate': 2.5166666666666666e-06, 'epoch': 1.76}\n{'loss': 0.8122, 'grad_norm': 1.928897500038147, 'learning_rate': 8.500000000000001e-07, 'epoch': 1.92}\n{'train_runtime': 3519.8664, 'train_samples_per_second': 2.841, 'train_steps_per_second': 0.71, 'total_flos': 3.181482344448e+16, 'train_loss': 0.9285867492675781, 'epoch': 2.0}\n","output_type":"stream"},{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2500, training_loss=0.9285867492675781, metrics={'train_runtime': 3519.8664, 'train_samples_per_second': 2.841, 'train_steps_per_second': 0.71, 'total_flos': 3.181482344448e+16, 'train_loss': 0.9285867492675781, 'epoch': 2.0})"},"metadata":{}}],"execution_count":113},{"cell_type":"code","source":"ls \"./tinyllama_finetuned\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:13:23.850243Z","iopub.execute_input":"2025-02-25T14:13:23.850537Z","iopub.status.idle":"2025-02-25T14:13:24.348958Z","shell.execute_reply.started":"2025-02-25T14:13:23.850517Z","shell.execute_reply":"2025-02-25T14:13:24.348148Z"}},"outputs":[{"name":"stdout","text":"adapter_config.json        special_tokens_map.json  tokenizer.model\nadapter_model.safetensors  tokenizer_config.json\nREADME.md                  tokenizer.json\n","output_type":"stream"}],"execution_count":115},{"cell_type":"code","source":"model.save_pretrained(\"./tinyllama_finetuned\")\ntokenizer.save_pretrained(\"./tinyllama_finetuned\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:13:20.363584Z","iopub.execute_input":"2025-02-25T14:13:20.363881Z","iopub.status.idle":"2025-02-25T14:13:20.853400Z","shell.execute_reply.started":"2025-02-25T14:13:20.363856Z","shell.execute_reply":"2025-02-25T14:13:20.852685Z"}},"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"('./tinyllama_finetuned/tokenizer_config.json',\n './tinyllama_finetuned/special_tokens_map.json',\n './tinyllama_finetuned/tokenizer.model',\n './tinyllama_finetuned/added_tokens.json',\n './tinyllama_finetuned/tokenizer.json')"},"metadata":{}}],"execution_count":114},{"cell_type":"code","source":"def generate_text(prompt):\n    # Format the prompt according to the model's expected format\n    formatted_prompt = f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n    \n    output = model.generate(\n        **inputs, \n        max_length=512, \n        temperature=0.7, \n        top_p=0.9, \n        do_sample=True,\n        repetition_penalty=1.2\n    )\n    \n    generated_text = tokenizer.decode(output[0], skip_special_tokens=False)\n    # Extract just the assistant's response\n    assistant_response = generated_text.split(\"<|im_start|>assistant\\n\")[-1].split(\"<|im_end|>\")[0]\n    return assistant_response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:13:39.875187Z","iopub.execute_input":"2025-02-25T14:13:39.875534Z","iopub.status.idle":"2025-02-25T14:13:39.881057Z","shell.execute_reply.started":"2025-02-25T14:13:39.875502Z","shell.execute_reply":"2025-02-25T14:13:39.880273Z"}},"outputs":[],"execution_count":116},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = input('What is on your mind?')\nprint(generate_text(prompt))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:37:00.838221Z","iopub.execute_input":"2025-02-25T14:37:00.838574Z","iopub.status.idle":"2025-02-25T14:37:31.693964Z","shell.execute_reply.started":"2025-02-25T14:37:00.838551Z","shell.execute_reply":"2025-02-25T14:37:31.693080Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"What is on your mind? explain hyperloop to a kid\n"},{"name":"stdout","text":"Introduction: Hyperloops, or Hyper-Velocity Transportation Systems (HVTS), are high-speed transport systems that travel at incredibly fast speeds through empty space. These futuristic vehicles are powered by advanced technology and can move people, goods, and even entire cargo containers between locations in seconds. However, not everyone understands the concept of hyperloops due to their complexity and technical nature. In this guide for parents who want to explain what hyperloops are all about to their children, we will break down everything you need to know about them in simple terms.\n\nHyperloops are Fast, Fun, and Exciting!\n\nImagine being able to hop onboard a ride like a roller coaster but without having to worry about slowing down when entering or exiting stations. That's what makes hyperloops so amazing! By using magnetic fields, these vehicles propel themselves upwards into the sky while travelling incredible distances with minimal effort from passengers. This means they save time, fuel, and energy compared to traditional methods such as trains, planes, or boats.\n\nHow Do They Work?\n\nA hyperloop consists of two independent sections connected together using magnetic levitation (maglev) technology. The first section is called the \"shaft\" where trains run along rails until reaching the second section called the \"tube.\" Here, the trains are propelled forward by powerful magnets and electric motors thanks to the magnetic field created by the shaft itself.\n\nThe tube segment has an airless insulation layer placed inside it, which helps prevent collisions during takeoff and landing. The whole system functions much like a subway train in urban areas, except instead of running on tracks, it moves through empty spaces below ground level.\n\nWhy Should We Care About Hyperloops?\n\nHere are some reasons why you should care about learning about hyperloops:\n\n1. Future Technologies - Whenever there's something new, people often ask if it'll replace existing technologies. But imagine how cool it would be if one day we could transport ourselves anywhere we wanted to go just by pressing a button!\n\n2. Improved Travel Experiences – With faster transit times, travelers\n","output_type":"stream"}],"execution_count":124},{"cell_type":"code","source":"ls \"/kaggle/working/fine_tuned_model\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:44:10.869138Z","iopub.execute_input":"2025-02-25T14:44:10.869445Z","iopub.status.idle":"2025-02-25T14:44:11.346585Z","shell.execute_reply.started":"2025-02-25T14:44:10.869422Z","shell.execute_reply":"2025-02-25T14:44:11.345744Z"}},"outputs":[{"name":"stdout","text":"adapter_config.json        special_tokens_map.json  tokenizer.model\nadapter_model.safetensors  tokenizer_config.json\nREADME.md                  tokenizer.json\n","output_type":"stream"}],"execution_count":126},{"cell_type":"code","source":"!zip -r fine_tuned_model.zip fine_tuned_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:49:01.339953Z","iopub.execute_input":"2025-02-25T14:49:01.340313Z","iopub.status.idle":"2025-02-25T14:49:02.196824Z","shell.execute_reply.started":"2025-02-25T14:49:01.340290Z","shell.execute_reply":"2025-02-25T14:49:02.195936Z"}},"outputs":[{"name":"stdout","text":"  adding: fine_tuned_model/ (stored 0%)\n  adding: fine_tuned_model/adapter_config.json (deflated 53%)\n  adding: fine_tuned_model/special_tokens_map.json (deflated 79%)\n  adding: fine_tuned_model/tokenizer.model (deflated 55%)\n  adding: fine_tuned_model/adapter_model.safetensors (deflated 8%)\n  adding: fine_tuned_model/README.md (deflated 66%)\n  adding: fine_tuned_model/tokenizer_config.json (deflated 68%)\n  adding: fine_tuned_model/tokenizer.json (deflated 85%)\n","output_type":"stream"}],"execution_count":130},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}